{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:46:13.599929Z",
     "start_time": "2018-04-09T13:46:13.223387Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Dynamic Routing Between Capsules\n",
    "# https://arxiv.org/pdf/1710.09829.pdf\n",
    "#\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from capsule_network import CapsuleNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:46:13.606236Z",
     "start_time": "2018-04-09T13:46:13.601641Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Settings.\n",
    "#\n",
    "learning_rate = 0.01\n",
    "\n",
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "# Stop training if loss goes below this threshold.\n",
    "early_stop_loss = 0.0001\n",
    "\n",
    "# printer interval\n",
    "log_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:46:20.705520Z",
     "start_time": "2018-04-09T13:46:13.607637Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Load MNIST dataset.\n",
    "#\n",
    "\n",
    "# Normalization for MNIST dataset.\n",
    "dataset_transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=dataset_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=False, download=True, transform=dataset_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "#\n",
    "# Create capsule network.\n",
    "#\n",
    "\n",
    "conv_inputs = 1\n",
    "conv_outputs = 256\n",
    "num_primary_units = 8\n",
    "primary_unit_size = 32 * 6 * 6  # fixme get from conv2d\n",
    "output_unit_size = 16\n",
    "\n",
    "network = CapsuleNetwork(image_width=28,\n",
    "                         image_height=28,\n",
    "                         image_channels=1,\n",
    "                         conv_inputs=conv_inputs,\n",
    "                         conv_outputs=conv_outputs,\n",
    "                         num_primary_units=num_primary_units,\n",
    "                         primary_unit_size=primary_unit_size,\n",
    "                         num_output_units=10, # one for each MNIST digit\n",
    "                         output_unit_size=output_unit_size).cuda()\n",
    "print(network)\n",
    "\n",
    "\n",
    "# Converts batches of class indices to classes of one-hot vectors.\n",
    "def to_one_hot(x, length):\n",
    "    batch_size = x.size(0)\n",
    "    x_one_hot = torch.zeros(batch_size, length)\n",
    "    for i in range(batch_size):\n",
    "        x_one_hot[i, x[i]] = 1.0\n",
    "    return x_one_hot\n",
    "\n",
    "# This is the test function from the basic Pytorch MNIST example, but adapted to use the capsule network.\n",
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        target_indices = target\n",
    "        target_one_hot = to_one_hot(target_indices, length=network.digits.num_units)\n",
    "\n",
    "        data, target = Variable(data, volatile=True).cuda(), Variable(target_one_hot).cuda()\n",
    "\n",
    "        output = network(data)\n",
    "\n",
    "        test_loss += network.loss(data, output, target, size_average=False).data[0] # sum up batch loss\n",
    "\n",
    "        v_mag = torch.sqrt((output**2).sum(dim=2, keepdim=True))\n",
    "\n",
    "        pred = v_mag.data.max(1, keepdim=True)[1].cpu()\n",
    "\n",
    "        correct += pred.eq(target_indices.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss,\n",
    "        correct,\n",
    "        len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "# This is the train function from the basic Pytorch MNIST example, but adapted to use the capsule network.\n",
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "def train(epoch):\n",
    "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    last_loss = None\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target_one_hot = to_one_hot(target, length=network.digits.num_units)\n",
    "\n",
    "        data, target = Variable(data).cuda(), Variable(target_one_hot).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = network(data)\n",
    "\n",
    "        loss = network.loss(data, output, target)\n",
    "        loss.backward()\n",
    "        last_loss = loss.data[0]\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data),\n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data[0]))\n",
    "\n",
    "        if last_loss < early_stop_loss:\n",
    "            break\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:46:32.369481Z",
     "start_time": "2018-04-09T13:46:20.708437Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    last_loss = train(epoch)\n",
    "    test()\n",
    "    if last_loss < early_stop_loss:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
